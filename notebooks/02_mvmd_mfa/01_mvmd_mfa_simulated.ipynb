{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Variational Mode Decomposition (MVMD) â€” Signal Decomposition Study\n",
    "\n",
    "## ðŸ§  What is MVMD?\n",
    "\n",
    "**MVMD** (Multivariate Variational Mode Decomposition) is an extension of the **Variational Mode Decomposition (VMD)** technique, adapted to **multichannel signals**. It decomposes a multivariate time series into a fixed number of **modes**, where each mode is:\n",
    "\n",
    "- **Band-limited** (localized in frequency)\n",
    "- Shared across all channels (common mode shapes)\n",
    "- Computed using a variational optimization framework (based on Wiener filtering and frequency demodulation)\n",
    "\n",
    "Unlike classical techniques like EMD or wavelets, **MVMD is non-recursive, robust to noise, and designed for multi-channel analysis**, making it especially suitable for biomedical, geophysical, and sensor-array signals.\n",
    "\n",
    "\n",
    "## ðŸ“ˆ Why is MVMD important?\n",
    "\n",
    "- It can **isolate frequency-specific patterns** in complex, noisy, multi-channel data.\n",
    "- It ensures that **each mode across channels is aligned**, i.e., mode 1 from all channels represents the same frequency band.\n",
    "- It supports applications like:\n",
    "  - Brain signal analysis (EEG, fMRI)\n",
    "  - Fault detection in mechanical systems\n",
    "  - Cross-spectral studies in sensor arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from pymultifracs.simul import mrw\n",
    "from mvmd_python import mvmd\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.signal import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameters\n",
    "# num_samples = 32768  # Length of the signal (number of samples)\n",
    "# num_channels = 4    # Number of channels\n",
    "\n",
    "# H = 0.8  # Hurst exponent (controls the fractality)\n",
    "# lam = np.sqrt(0.7)  # Lambda, intermittency parameter\n",
    "# L = 1024  # Integral scale\n",
    "# sigma = 1  # Standard deviation of noise\n",
    "\n",
    "# # 1. Generate a shared low-frequency component\n",
    "# t = np.linspace(0, 1, num_samples)\n",
    "# shared_freq_signal = np.sin(2 * np.pi * 0.01 * t)  # Low frequency sinusoid\n",
    "\n",
    "# # 2. Generate different frequency components for each channel\n",
    "# signal = np.zeros((num_samples, num_channels))\n",
    "\n",
    "# for i in range(num_channels):\n",
    "#     if i < 3:  # Use MRW to introduce multifractality in some channels\n",
    "#         signal[:, i] = mrw(shape=(num_samples, 1), H=H, lam=lam, L=L, sigma=sigma).squeeze()\n",
    "#     else:  # Use a random frequency component for the other channels\n",
    "#         noise = np.random.randn(num_samples) * 0.2\n",
    "#         signal[:, i] = shared_freq_signal + noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1:\n",
    "\n",
    "To evaluate the performance of **Multivariate Variational Mode Decomposition (MVMD)**, we created a **controlled synthetic 3-channel signal** with known frequency components. The idea is to simulate a realistic multichannel scenario where all channels share a common base frequency, but each also contains unique features.\n",
    "\n",
    "### Signal Design:\n",
    "\n",
    "- **Duration**: 1 second  \n",
    "- **Sampling rate**: 32,768 Hz (high-resolution to simulate realistic biomedical signals)  \n",
    "- **Channels**: 3 parallel signals with shared and distinct frequency components\n",
    "\n",
    "### Signal Composition:\n",
    "\n",
    "- **Channel 1**:  \n",
    "  - Common **36 Hz** tone  \n",
    "  - Added **2 Hz** low-frequency component  \n",
    "- **Channel 2**:  \n",
    "  - Common **36 Hz** tone  \n",
    "  - Added **24 Hz** medium-frequency component  \n",
    "- **Channel 3**:  \n",
    "  - Common **36 Hz** tone  \n",
    "  - Added **Gaussian noise** (random fluctuations)\n",
    "\n",
    "### Why this setup?\n",
    "\n",
    "This structure allows us to test whether MVMD can:\n",
    "- Separate the **shared 36 Hz tone** across all channels into a clean mode\n",
    "- Isolate the **unique frequencies (2 Hz, 24 Hz)** present in individual channels\n",
    "- Handle **noisy inputs** by producing stable and meaningful mode decompositions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Parameters\n",
    "T = 32768  # Number of time points\n",
    "t = np.linspace(0, 1, T)  # Time vector\n",
    "shared_frequency = 36  # Hz\n",
    "num_channels = 3  # Number of channels (Channels 1, 2, 3)\n",
    "signal = np.zeros((T, num_channels))  # Create a signal array with zeros\n",
    "\n",
    "# Channel 1: 36 Hz tone + 2 Hz tone\n",
    "signal[:, 0] = np.sin(2 * np.pi * shared_frequency * t) + np.sin(2 * np.pi * 2 * t)  # Channel 1\n",
    "\n",
    "# Channel 2: 36 Hz tone + 24 Hz tone\n",
    "signal[:, 1] = np.sin(2 * np.pi * shared_frequency * t) + np.sin(2 * np.pi * 24 * t)  # Channel 2\n",
    "\n",
    "# Channel 3: 36 Hz tone + Noise\n",
    "signal[:, 2] = np.sin(2 * np.pi * shared_frequency * t) + np.random.normal(0, 0.2, T)  # Channel 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = signal.shape[1]\n",
    "T = signal.shape[0]\n",
    "offset = 5\n",
    "\n",
    "channel_colors = ['blue', 'red', 'green', 'orange']\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=num_channels, cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.02,\n",
    ")\n",
    "\n",
    "for i in range(num_channels):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=np.arange(T),\n",
    "            y=signal[:, i] + i * offset,\n",
    "            mode='lines',\n",
    "            name=f\"Channel {i+1}\",\n",
    "            line=dict(width=1, color=channel_colors[i])\n",
    "        ),\n",
    "        row=i + 1, col=1\n",
    "    )\n",
    "    # Hide y-axis tick labels\n",
    "    fig.update_yaxes(\n",
    "        showticklabels=False,\n",
    "        row=i + 1, col=1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=100 * num_channels,\n",
    "    width=1000,\n",
    "    title=\"Multichannel Signal (Colored by Group & Vertically Spaced)\",\n",
    "    template=\"plotly_white\",\n",
    "    showlegend=True,\n",
    "    legend=dict(\n",
    "        orientation=\"v\",\n",
    "        yanchor=\"top\",\n",
    "        y=1,\n",
    "        xanchor=\"left\",\n",
    "        x=1.02\n",
    "    ),\n",
    "    \n",
    "    # Add global y-axis label using annotation\n",
    "    annotations=[\n",
    "        dict(\n",
    "            text=\"Amplitude \",\n",
    "            xref=\"paper\", yref=\"paper\",\n",
    "            x=-0.06, y=0.5,\n",
    "            showarrow=False,\n",
    "            textangle=-90,\n",
    "            font=dict(size=14)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Time\", row=num_channels, col=1)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 2000  # Balancing parameter\n",
    "tau = 0.  # Time-step of dual ascent\n",
    "K = 3  # Number of modes to recover\n",
    "DC = 0  # No DC component\n",
    "init = 1  # Initialize frequencies uniformly\n",
    "tol = 1e-7  # Convergence tolerance\n",
    "max_N = 50  # Maximum iterations\n",
    "\n",
    "u, u_hat, omega = mvmd(signal, alpha, tau, K, DC, init, tol, max_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "K = u.shape[0]  # Number of modes (4)\n",
    "T = u.shape[2]  # Number of time points (32768)\n",
    "num_channels = u.shape[1]  # Number of channels (8)\n",
    "\n",
    "# Desired number of time points after resampling\n",
    "num_resampled_points = 1000  # You can adjust this value\n",
    "\n",
    "# Resample each mode and each channel using scipy's resample\n",
    "u_resampled = np.zeros((K, num_channels, num_resampled_points))\n",
    "\n",
    "for k in range(K):\n",
    "    for i in range(num_channels):\n",
    "        u_resampled[k, i, :] = resample(u[k, i, :].cpu().numpy(), num_resampled_points)\n",
    "\n",
    "# Time vector for resampled data\n",
    "x_resampled = np.linspace(0, T-1, num_resampled_points)\n",
    "\n",
    "# Channel colors (assign colors based on your preferred scheme)\n",
    "channel_colors = ['blue', 'red', 'green', 'orange', 'purple', 'cyan', 'magenta', 'black']  # Adjust if needed\n",
    "\n",
    "# Create subplots: 1 for each mode (K rows)\n",
    "fig, axs = plt.subplots(K, 1, figsize=(12, 3 * K), sharex=True)\n",
    "\n",
    "# Plot each mode (from uâ‚ to uâ‚–) for each channel\n",
    "for k in range(K):\n",
    "    for i in range(num_channels):\n",
    "        axs[k].plot(x_resampled, u_resampled[k, i, :], label=f\"Channel {i + 1}\", color=channel_colors[i], linewidth=0.8)\n",
    "\n",
    "    axs[k].set_title(f\"Mode u{k + 1}\")\n",
    "    axs[k].set_ylabel(\"Amplitude\")\n",
    "    axs[k].grid(True)\n",
    "    axs[k].legend(loc=\"upper right\", fontsize=8)\n",
    "\n",
    "# Set x-axis label for the last row\n",
    "axs[K - 1].set_xlabel(\"Time (samples)\")\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "K = u.shape[0]  # Number of modes (4)\n",
    "T = u.shape[2]  # Number of time points (32768)\n",
    "num_channels = u.shape[1]  # Number of channels (3, after removing the 4th channel)\n",
    "\n",
    "# Time vector (x-axis)\n",
    "x = np.arange(T)\n",
    "\n",
    "# Create subplots: 5 rows, 2 columns for the original data and modes\n",
    "fig, axs = plt.subplots(5, 3, figsize=(12, 12), sharex=True)\n",
    "\n",
    "# Channel colors (assign colors based on your preferred scheme)\n",
    "channel_colors = ['blue', 'red', 'green','purple']  # Adjust as needed\n",
    "\n",
    "# Channel indices for column 1 and 2\n",
    "channel_indices = [0, 1, 2]\n",
    "\n",
    "# Define the y-axis limits for all subplots (to be the same for all)\n",
    "y_limit = (-1.5, 1.5)  # You can adjust this to match the amplitude range you want for all modes\n",
    "\n",
    "# Loop through the channels (channel 0 for column 1, channel 2 for column 2)\n",
    "for col_idx, channel in enumerate(channel_indices):\n",
    "    # Plot original data in the first row (black color)\n",
    "    axs[0, col_idx].plot(x, signal[:, channel], color='black', label='Original Data')\n",
    "    axs[0, col_idx].set_title(f\"Channel {channel + 1}\")\n",
    "    axs[0, col_idx].set_ylabel('Amplitude')\n",
    "    axs[0, col_idx].legend(loc='upper right')\n",
    "    \n",
    "    # Loop through the modes (u1 to u4) and plot in rows 2 to 5\n",
    "    for k in range(K):\n",
    "        axs[k + 1, col_idx].plot(x, u[k, channel, :].cpu().numpy(), label=f\"Mode u{k + 1}\", color=channel_colors[k], linewidth=0.8)\n",
    "        axs[k + 1, col_idx].set_ylabel('Amplitude')\n",
    "        axs[k + 1, col_idx].legend(loc='upper right')\n",
    "\n",
    "        # Set the same y-axis limits for all subplots\n",
    "        axs[k + 1, col_idx].set_ylim(y_limit)\n",
    "\n",
    "# Set x-axis label for the last row (shared)\n",
    "axs[3, 0].set_xlabel(\"Time (samples)\")\n",
    "axs[3, 1].set_xlabel(\"Time (samples)\")\n",
    "axs[3, 2].set_xlabel(\"Time (samples)\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "\n",
    "# Use your actual MVMD output\n",
    "# u.shape should be [K, C, T]\n",
    "# If it's torch.Tensor, move to CPU and convert\n",
    "u_np = u.cpu().numpy() if hasattr(u, 'cpu') else u  # [K, C, T]\n",
    "\n",
    "fs = 32768  # Sampling rate\n",
    "K, C, T = u_np.shape\n",
    "\n",
    "# Compute Welch PSD for each mode and channel\n",
    "f_axis = None\n",
    "psd_matrix = []\n",
    "\n",
    "for k in range(K):\n",
    "    psd_channels = []\n",
    "    for c in range(C):\n",
    "        f, Pxx = welch(u_np[k, c, :], fs=fs, nperseg=2048)\n",
    "        psd_channels.append(Pxx)\n",
    "    psd_matrix.append(psd_channels)\n",
    "    if f_axis is None:\n",
    "        f_axis = f\n",
    "\n",
    "# Convert to NumPy array: [K, C, F]\n",
    "psd_matrix = np.array(psd_matrix)\n",
    "\n",
    "# Plot: dB scale\n",
    "fig, axs = plt.subplots(\n",
    "    int(np.ceil(K / 2)), 2, figsize=(10, 2.8 * int(np.ceil(K / 2))), sharex=True\n",
    ")\n",
    "axs = axs.ravel()\n",
    "\n",
    "for k in range(K):\n",
    "    for c in range(C):\n",
    "        axs[k].plot(f_axis, 10 * np.log10(psd_matrix[k, c] + 1e-12), label=f'Channel {c+1}')\n",
    "\n",
    "    axs[k].set_title(f'Mode {k+1}')\n",
    "    axs[k].set_xlim(0, 80)\n",
    "    axs[k].set_ylim(-80, 30)\n",
    "    axs[k].set_xlabel(\"Frequency (Hz)\")\n",
    "    axs[k].set_ylabel(\"Power (dB)\")\n",
    "    axs[k].grid(True)\n",
    "    axs[k].legend()\n",
    "\n",
    "# Clean up unused subplots if K is odd\n",
    "for i in range(K, len(axs)):\n",
    "    fig.delaxes(axs[i])\n",
    "\n",
    "fig.suptitle(\"MVMD Decomposition â€“ PSD per Mode (dB scale)\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import welch\n",
    "\n",
    "fs = 32768\n",
    "K = u.shape[0]\n",
    "C = u.shape[1]\n",
    "\n",
    "for k in range(K):\n",
    "    for c in range(C):\n",
    "        mode_signal = u[k, c, :].cpu().numpy()\n",
    "        f, Pxx = welch(mode_signal, fs=fs, nperseg=2048)\n",
    "        peak_freq = f[np.argmax(Pxx)]\n",
    "        print(f\"Mode {k+1}, Channel {c+1}: Welch peak at {peak_freq:.2f} Hz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming omega is already defined as a tensor or numpy array\n",
    "# If omega is a PyTorch tensor, ensure it's on the CPU before converting to NumPy\n",
    "omega_real = omega.real.cpu().numpy()  # Convert omega to real part (NumPy array)\n",
    "\n",
    "# Number of modes and iterations (samples)\n",
    "K = omega_real.shape[1]\n",
    "iterations = omega_real.shape[0]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each mode (from mode 1 to mode K)\n",
    "for k in range(K):\n",
    "    plt.plot(np.arange(iterations), omega_real[:, k], label=f\"Mode {k + 1}\")\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title(\"Center Frequencies (Omega) for Each Mode\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.legend(title=\"Modes\", fontsize=10)\n",
    "plt.grid(True)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy if not already\n",
    "u_np = u.cpu().numpy()  # shape: [K, num_channels, T]\n",
    "\n",
    "K = u_np.shape[0]\n",
    "num_channels = u_np.shape[1]\n",
    "T = u_np.shape[2]\n",
    "\n",
    "# Normalize each mode per channel\n",
    "u_norm = np.zeros_like(u_np)\n",
    "for k in range(K):\n",
    "    for c in range(num_channels):\n",
    "        mode = u_np[k, c, :]\n",
    "        u_norm[k, c, :] = (mode - np.mean(mode)) / np.std(mode)\n",
    "\n",
    "# Initialize correlation matrix\n",
    "corr_matrix = np.zeros((K, K))\n",
    "\n",
    "# Compute cross-correlation between modes, averaged across channels\n",
    "for i in range(K):\n",
    "    for j in range(K):\n",
    "        corr_values = []\n",
    "        for c in range(num_channels):\n",
    "            corr = np.corrcoef(u_norm[i, c, :], u_norm[j, c, :])[0, 1]\n",
    "            corr_values.append(corr)\n",
    "        corr_matrix[i, j] = np.mean(corr_values)\n",
    "\n",
    "# Plot correlation matrix with values\n",
    "plt.figure(figsize=(6, 5))\n",
    "im = plt.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.colorbar(im, label='Average Pearson Correlation')\n",
    "plt.title('Cross-Correlation Matrix Between Modes\\n(Averaged Over Channels)')\n",
    "plt.xticks(np.arange(K), [f'Mode {k+1}' for k in range(K)])\n",
    "plt.yticks(np.arange(K), [f'Mode {k+1}' for k in range(K)])\n",
    "plt.xlabel('Mode')\n",
    "plt.ylabel('Mode')\n",
    "\n",
    "# Annotate correlation values\n",
    "for i in range(K):\n",
    "    for j in range(K):\n",
    "        plt.text(j, i, f\"{corr_matrix[i, j]:.2f}\", ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ðŸ§® Step-by-step: Compute correlation between Mode 1 and Mode 2 for 4 channels\n",
    "\n",
    "For channel 1:\n",
    "    corr(u1[:, 0], u2[:, 0])\n",
    "\n",
    "For channel 2:\n",
    "    corr(u1[:, 1], u2[:, 1])\n",
    "\n",
    "For channel 3:\n",
    "    corr(u1[:, 2], u2[:, 2])\n",
    "\n",
    "For channel 4:\n",
    "    corr(u1[:, 3], u2[:, 3])\n",
    "\n",
    "âœ… Total: 4 correlation values\n",
    "(one per channel, comparing the same channel in both modes)\n",
    "\n",
    "Then:\n",
    "    Average the 4 values to get a single correlation score between Mode 1 and Mode 2\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§  MVMD Decomposition â€“ Interpretation Summary\n",
    "\n",
    "#### ðŸ”¹ 1. Time-Domain Modes\n",
    "- **Mode 1** (blue): High-frequency, present in all channels â†’ captures the **shared 36â€¯Hz tone**.\n",
    "- **Mode 2** (red): Low-frequency, strong in Channels 1 & 3 â†’ isolates the **low-frequency component**, maybe 2â€¯Hz + noise.\n",
    "- **Mode 3** (green): Mid-frequency, clear in Channel 2 â†’ corresponds to the **24â€¯Hz tone** + noise.\n",
    "\n",
    "#### ðŸ”¹ 2. Frequency-Domain PSD (dB)\n",
    "- **Mode 1**: Peak near **36â€¯Hz** across all channels.\n",
    "- **Mode 2**: Low-energy peak near **2â€“5â€¯Hz**.\n",
    "- **Mode 3**: Peak around **24â€¯Hz**, strongest in Channel 2.\n",
    "\n",
    "#### ðŸ”¹ 3. Cross-Correlation Matrix\n",
    "- Modes are **uncorrelated** (off-diagonal â‰ˆ 0).\n",
    "- Confirms clean spectral and temporal separation by MVMD.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Conclusion**:  \n",
    "MVMD successfully decomposed the multi-channel signal into **distinct, interpretable frequency bands**.  \n",
    "Time-domain and frequency-domain results are consistent, and each mode is well-isolated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal parameters\n",
    "N = 32768  # Number of time points\n",
    "L = 512    # Integral scale\n",
    "\n",
    "# Define multifractality parameters for each channel\n",
    "# Channels 1 & 2 = strong multifractality (high lambda)\n",
    "# Channels 3 & 4 = weak multifractality (low lambda)\n",
    "H_values = [0.3, 0.7, 0.3, 0.7]              # Hurst exponents\n",
    "lambda_values = [0.3, 0.35, 0.05, 0.1]       # Intermittency Î»\n",
    "\n",
    "# Generate each channel with specified multifractal parameters\n",
    "channels = []\n",
    "for H, lam in zip(H_values, lambda_values):\n",
    "    x = mrw((N,1), H=H, lam=lam, L=L)\n",
    "    channels.append(x)\n",
    "\n",
    "# Stack into a 2D array: shape (T, 4)\n",
    "signal = np.stack(channels, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2:\n",
    "\n",
    "To evaluate the behavior of MVMD on **multifractal time series**, we created a **4-channel signal** using the **Multifractal Random Walk (MRW)** model. This setup simulates signals with distinct levels of **multifractality**, allowing us to observe whether MVMD can distinguish between them in a multivariate setting.\n",
    "\n",
    "### Signal Design:\n",
    "\n",
    "- **Length**: 32,768 time points  \n",
    "- **Channels**: 4 independent realizations  \n",
    "- **Model**: MRW (Multifractal Random Walk, Bacry et al., 2001)  \n",
    "- **Integral scale**: 512  \n",
    "- **Sampling method**: Circulant Matrix Embedding (CME)\n",
    "\n",
    "### Multifractality Parameters:\n",
    "\n",
    "| Channel | Hurst Exponent (H) | Intermittency (Î») | Interpretation                      |\n",
    "|---------|--------------------|-------------------|--------------------------------------|\n",
    "| 1       | 0.3                | 0.30              | Strong multifractality               |\n",
    "| 2       | 0.7                | 0.35              | Strong multifractality               |\n",
    "| 3       | 0.3                | 0.05              | Weak multifractality (quasi-monofractal) |\n",
    "| 4       | 0.7                | 0.10              | Weak multifractality (quasi-monofractal) |\n",
    "\n",
    "### Why this setup?\n",
    "\n",
    "This configuration lets us test whether MVMD is able to:\n",
    "- Separate modes based on **underlying multifractal properties** (not just frequency)\n",
    "- Distinguish between **strongly vs. weakly multifractal** dynamics\n",
    "- Adapt to signals with **heterogeneous temporal complexity**\n",
    "\n",
    "Such signals are representative of **physiological data** (e.g., EEG, fMRI, HRV) where multifractality may vary between regions, conditions, or subjects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal parameters\n",
    "N = 32768  # Number of time points\n",
    "L = 512    # Integral scale\n",
    "\n",
    "# Define multifractality parameters for each channel\n",
    "# Channels 1 & 2 = strong multifractality (high lambda)\n",
    "# Channels 3 & 4 = weak multifractality (low lambda)\n",
    "# Define multifractality parameters for each channel (Hurst exponents and lambda values)\n",
    "H_values = [0.3, 0.7, 0.3, 0.7]             # Hurst exponents\n",
    "lambda_values = [0.3, 0.35, 0.05, 0.1]      # Intermittency Î»\n",
    "\n",
    "# Generate each channel with specified multifractal parameters using MRW\n",
    "channels = []\n",
    "for H, lam in zip(H_values, lambda_values):\n",
    "    x = mrw((N,1), H=H, lam=lam, L=L)  # Generate MRW signal for each channel\n",
    "    channels.append(torch.tensor(x).squeeze())  # Convert to tensor and remove unnecessary dimension\n",
    "\n",
    "# Stack all channels into a tensor (shape: [4, 32768])\n",
    "signal = torch.stack(channels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot all 4 channels\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(4):\n",
    "    plt.plot(signal[:, i], label=f'Channel {i+1} (H={H_values[i]}, Î»={lambda_values[i]})')\n",
    "plt.title(\"ðŸŒ€ Simulated MRW Signals with Varying Multifractality\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal_mvmd = np.expand_dims(signal.T, axis=0)  # also wrong here\n",
    "signal = np.squeeze(signal)      # removes the last dim â†’ shape: (32768, 4)\n",
    "signal_mvmd = signal.T  \n",
    "print(signal.shape)  # Should print: (4, 32768)\n",
    "print(signal_mvmd.shape)  # Should print: (4, 32768)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = 2000  # Balancing parameter\n",
    "tau = 0.  # Time-step of dual ascent\n",
    "K = 3  # Number of modes to recover\n",
    "DC = 0  # No DC component\n",
    "init = 1  # Initialize frequencies uniformly\n",
    "tol = 1e-7  # Convergence tolerance\n",
    "max_N = 50  # Maximum iterations\n",
    "\n",
    "u, u_hat, omega = mvmd(signal, alpha, tau, K, DC, init, tol, max_N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mfa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
